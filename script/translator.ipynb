{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "af8d0821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def findOccurrences(s, ch):\n",
    "    return [i for i, letter in enumerate(s) if letter == ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7bff6673",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "27aa35fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"output.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "84f9273a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "Verifiable and Provably Secure Machine Unlearning\n",
      "https://arxiv.org/abs/2210.09126\n",
      "arXiv\n",
      "2022\n",
      "https://github.com/cleverhans-lab/verifiable-unlearning\n",
      "Model-Agnostic\n",
      "----\n",
      "Machine Unlearning Method Based On Projection Residual\n",
      "https://arxiv.org/abs/2209.15276\n",
      "DSAA\n",
      "2022\n",
      "-\n",
      "Model-Agnostic\n",
      "----\n",
      "Hard to Forget: Poisoning Attacks on Certified Machine Unlearning\n",
      "https://ojs.aaai.org/index.php/AAAI/article/view/20736\n",
      "AAAI\n",
      "2022\n",
      "https://github.com/ngmarchant/attack-unlearning\n",
      "Model-Agnostic\n",
      "----\n",
      "Markov Chain Monte Carlo-Based Machine Unlearning: Unlearning What Needs to be Forgotten\n",
      "https://dl.acm.org/doi/abs/10.1145/3488932.3517406\n",
      "ASIA CCS\n",
      "2022\n",
      "-\n",
      "Model-Agnostic\n",
      "----\n",
      "Can Bad Teaching Induce Forgetting? Unlearning in Deep Networks using an Incompetent Teacher\n",
      "https://arxiv.org/abs/2205.08096\n",
      "arXiv\n",
      "2022\n",
      "-\n",
      "Model-Agnostic\n",
      "----\n",
      "Learn to Forget: Machine Unlearning Via Neuron Masking\n",
      "https://ieeexplore.ieee.org/abstract/document/9844865?casa_token=_eowH3BTt1sAAAAA:X0uCpLxOwcFRNJHoo3AtA0ay4t075_cSptgTMznsjusnvgySq-rJe8GC285YhWG4Q0fUmP9Sodw0\n",
      "IEEE\n",
      "2021\n",
      "-\n",
      "Model-Agnostic\n",
      "----\n",
      "Adaptive Machine Unlearning\n",
      "https://proceedings.neurips.cc/paper/2021/hash/87f7ee4fdb57bdfd52179947211b7ebb-Abstract.html\n",
      "NeurIPS\n",
      "2021\n",
      "https://github.com/ChrisWaites/adaptive-machine-unlearning\n",
      "Model-Agnostic\n",
      "----\n",
      "Descent-to-Delete: Gradient-Based Methods for Machine Unlearning\n",
      "https://proceedings.mlr.press/v132/neel21a.html\n",
      "ALT\n",
      "2021\n",
      "-\n",
      "Model-Agnostic\n",
      "----\n",
      "Machine Unlearning via Algorithmic Stability\n",
      "https://proceedings.mlr.press/v134/ullah21a.html\n",
      "COLT\n",
      "2021\n",
      "-\n",
      "Model-Agnostic\n",
      "----\n",
      "Knowledge-Adaptation Priors\n",
      "https://proceedings.neurips.cc/paper/2021/hash/a4380923dd651c195b1631af7c829187-Abstract.html\n",
      "NeurIPS\n",
      "2021\n",
      "https://github.com/team-approx-bayes/kpriors\n",
      "Model-Agnostic\n",
      "----\n",
      "PrIU: A Provenance-Based Approach for Incrementally Updating Regression Models\n",
      "https://dl.acm.org/doi/abs/10.1145/3318464.3380571\n",
      "NeurIPS\n",
      "2020\n",
      "-\n",
      "Model-Agnostic\n",
      "----\n",
      "Eternal Sunshine of the Spotless Net: Selective Forgetting in Deep Networks\n",
      "https://arxiv.org/abs/1911.04933\n",
      "CVPR\n",
      "2020\n",
      "-\n",
      "Model-Agnostic\n",
      "----\n",
      "Certified Data Removal from Machine Learning Models\n",
      "https://proceedings.mlr.press/v119/guo20c.html\n",
      "ICML\n",
      "2020\n",
      "-\n",
      "Model-Agnostic\n",
      "----\n",
      "A Novel Online Incremental and Decremental Learning Algorithm Based on Variable Support Vector Machine\n",
      "https://link.springer.com/article/10.1007/s10586-018-1772-4\n",
      "Cluster Computing\n",
      "2019\n",
      "-\n",
      "Model-Agnostic\n",
      "----\n",
      "Making AI Forget You: Data Deletion in Machine Learning\n",
      "https://papers.nips.cc/paper/2019/hash/cb79f8fa58b91d3af6c9c991f63962d3-Abstract.html\n",
      "NeurIPS\n",
      "2019\n",
      "-\n",
      "Model-Agnostic\n",
      "----\n",
      "Understanding Black-box Predictions via Influence Functions\n",
      "https://proceedings.mlr.press/v70/koh17a.html\n",
      "ICML\n",
      "2017\n",
      "https://github.com/kohpangwei/influence-release\n",
      "Model-Agnostic\n",
      "----\n",
      "Towards Making Systems Forget with Machine Unlearning\n",
      "https://dl.acm.org/doi/10.1109/SP.2015.35\n",
      "S&P\n",
      "2015\n",
      "-\n",
      "Model-Agnostic\n",
      "----\n",
      "Incremental and decremental training for linear classification\n",
      "https://dl.acm.org/doi/10.1145/2623330.2623661\n",
      "KDD\n",
      "2014\n",
      "https://www.csie.ntu.edu.tw/~cjlin/papers/ws/\n",
      "Model-Agnostic\n",
      "----\n",
      "Multiple Incremental Decremental Learning of Support Vector Machines\n",
      "https://dl.acm.org/doi/10.5555/2984093.2984196\n",
      "NIPS\n",
      "2009\n",
      "-\n",
      "Model-Agnostic\n",
      "----\n",
      "Incremental and Decremental Learning for Linear Support Vector Machines\n",
      "https://dl.acm.org/doi/10.5555/1776814.1776838\n",
      "ICANN\n",
      "2007\n",
      "-\n",
      "Model-Agnostic\n",
      "----\n",
      "Decremental Learning Algorithms for Nonlinear Langrangian and Least Squares Support Vector Machines\n",
      "https://www.semanticscholar.org/paper/Decremental-Learning-Algorithms-for-Nonlinear-and-Duan-Li/312c677f0882d0dfd60bfd77346588f52aefd10f\n",
      "OSB\n",
      "2007\n",
      "-\n",
      "Model-Agnostic\n",
      "----\n",
      "Multicategory Incremental Proximal Support Vector Classifiers\n",
      "https://link.springer.com/chapter/10.1007/978-3-540-45224-9_54\n",
      "KES\n",
      "2003\n",
      "-\n",
      "Model-Agnostic\n",
      "----\n",
      "Incremental and Decremental Proximal Support Vector Classification using Decay Coefficients\n",
      "https://link.springer.com/chapter/10.1007/978-3-540-45228-7_42\n",
      "DaWak\n",
      "2003\n",
      "-\n",
      "Model-Agnostic\n",
      "----\n",
      "Incremental and Decremental Support Vector Machine Learning\n",
      "https://dl.acm.org/doi/10.5555/3008751.3008808\n",
      "NeurIPS\n",
      "2000\n",
      "-\n",
      "Model-Agnostic\n",
      "----\n",
      "Memory-Based Model Editing at Scale\n",
      "https://proceedings.mlr.press/v162/mitchell22a/mitchell22a.pdf\n",
      "MLR\n",
      "2022\n",
      "https://sites.google.com/view/serac-editing\n",
      "Model-Intrinsic\n",
      "----\n",
      "Machine Unlearning for Image Retrieval: A Generative Scrubbing Approach\n",
      "https://dl.acm.org/doi/abs/10.1145/3503161.3548378\n",
      "MM\n",
      "2022\n",
      "-\n",
      "Model-Intrinsic\n",
      "----\n",
      "Machine Unlearning: Linear Filtration for Logit-based Classifiers\n",
      "https://link.springer.com/article/10.1007/s10994-022-06178-9\n",
      "Machine Learning\n",
      "2022\n",
      "-\n",
      "Model-Intrinsic\n",
      "----\n",
      "Deep Unlearning via Randomized Conditionally Independent Hessians\n",
      "https://openaccess.thecvf.com/content/CVPR2022/html/Mehta_Deep_Unlearning_via_Randomized_Conditionally_Independent_Hessians_CVPR_2022_paper.html\n",
      "CVPR\n",
      "2022\n",
      "https://github.com/vsingh-group/LCODEC-deep-unlearning\n",
      "Model-Intrinsic\n",
      "----\n",
      "Variational Bayesian unlearning\n",
      "https://dl.acm.org/doi/abs/10.5555/3495724.3497068\n",
      "NeurIPS\n",
      "2022\n",
      "-\n",
      "Model-Intrinsic\n",
      "----\n",
      "Revisiting Machine Learning Training Process for Enhanced Data Privacy\n",
      "https://dl.acm.org/doi/abs/10.1145/3474124.3474208\n",
      "IC3\n",
      "2021\n",
      "-\n",
      "Model-Intrinsic\n",
      "----\n",
      "Knowledge Removal in Sampling-based Bayesian Inference\n",
      "https://openreview.net/forum?id=dTqOcTUOQO\n",
      "ICLR\n",
      "2021\n",
      "https://github.com/fshp971/mcmc-unlearning\n",
      "Model-Intrinsic\n",
      "----\n",
      "Mixed-Privacy Forgetting in Deep Networks\n",
      "https://openaccess.thecvf.com/content/CVPR2021/html/Golatkar_Mixed-Privacy_Forgetting_in_Deep_Networks_CVPR_2021_paper.html\n",
      "CVPR\n",
      "2021\n",
      "-\n",
      "Model-Intrinsic\n",
      "----\n",
      "HedgeCut: Maintaining Randomised Trees for Low-Latency Machine Unlearning\n",
      "https://dl.acm.org/doi/abs/10.1145/3448016.3457239\n",
      "SIGMOD\n",
      "2021\n",
      "https://github.com/schelterlabs/hedgecut\n",
      "Model-Intrinsic\n",
      "----\n",
      "A Unified PAC-Bayesian Framework for Machine Unlearning via Information Risk Minimization\n",
      "https://ieeexplore.ieee.org/abstract/document/9596170\n",
      "MLSP\n",
      "2021\n",
      "-\n",
      "Model-Intrinsic\n",
      "----\n",
      "DeepObliviate: A Powerful Charm for Erasing Data Residual Memory in Deep Neural Networks\n",
      "https://arxiv.org/abs/2105.06209\n",
      "arXiv\n",
      "2021\n",
      "-\n",
      "Model-Intrinsic\n",
      "----\n",
      "Bayesian Inference Forgetting\n",
      "https://arxiv.org/abs/2101.06417\n",
      "arXiv\n",
      "2021\n",
      "https://github.com/fshp971/BIF\n",
      "Model-Intrinsic\n",
      "----\n",
      "Approximate Data Deletion from Machine Learning Models\n",
      "https://proceedings.mlr.press/v130/izzo21a.html\n",
      "AISTATS\n",
      "2021\n",
      "https://github.com/zleizzo/datadeletion\n",
      "Model-Intrinsic\n",
      "----\n",
      "Online Forgetting Process for Linear Regression Models\n",
      "https://proceedings.mlr.press/v130/li21a.html\n",
      "AISTATS\n",
      "2021\n",
      "-\n",
      "Model-Intrinsic\n",
      "----\n",
      "Forgetting Outside the Box: Scrubbing Deep Networks of Information Accessible from Input-Output Observations\n",
      "https://link.springer.com/chapter/10.1007/978-3-030-58526-6_23\n",
      "ECCV\n",
      "2020\n",
      "-\n",
      "Model-Intrinsic\n",
      "----\n",
      "Influence Functions in Deep Learning Are Fragile\n",
      "https://www.semanticscholar.org/paper/Influence-Functions-in-Deep-Learning-Are-Fragile-Basu-Pope/098076a2c90e42c81b843bf339446427c2ff02ed\n",
      "arXiv\n",
      "2020\n",
      "-\n",
      "Model-Intrinsic\n",
      "----\n",
      "Deep Autoencoding Topic Model With Scalable Hybrid Bayesian Inference\n",
      "https://ieeexplore.ieee.org/document/9121755\n",
      "IEEE\n",
      "2020\n",
      "-\n",
      "Model-Intrinsic\n",
      "----\n",
      "Eternal Sunshine of the Spotless Net: Selective Forgetting in Deep Networks\n",
      "https://arxiv.org/abs/1911.04933\n",
      "CVPR\n",
      "2020\n",
      "-\n",
      "Model-Intrinsic\n",
      "----\n",
      "Uncertainty in Neural Networks: Approximately Bayesian Ensembling\n",
      "https://proceedings.mlr.press/v108/pearce20a.html\n",
      "AISTATS\n",
      "2020\n",
      "https://teapearce.github.io/portfolio/github_io_1_ens/\n",
      "Model-Intrinsic\n",
      "----\n",
      "Certified Data Removal from Machine Learning Models\n",
      "https://proceedings.mlr.press/v119/guo20c.html\n",
      "ICML\n",
      "2020\n",
      "-\n",
      "Model-Intrinsic\n",
      "----\n",
      "DeltaGrad: Rapid retraining of machine learning models\n",
      "https://proceedings.mlr.press/v119/wu20b.html\n",
      "ICML\n",
      "2020\n",
      "https://github.com/thuwuyinjun/DeltaGrad\n",
      "Model-Intrinsic\n",
      "----\n",
      "Making AI Forget You: Data Deletion in Machine Learning\n",
      "https://papers.nips.cc/paper/2019/hash/cb79f8fa58b91d3af6c9c991f63962d3-Abstract.html\n",
      "NeurIPS\n",
      "2019\n",
      "-\n",
      "Model-Intrinsic\n",
      "----\n",
      "Neural Text Degeneration With Unlikelihood Training\n",
      "https://arxiv.org/abs/1908.04319\n",
      "arXiv\n",
      "2019\n",
      "https://github.com/facebookresearch/unlikelihood_training\n",
      "Model-Intrinsic\n",
      "----\n",
      "Bayesian Neural Networks with Weight Sharing Using Dirichlet Processes\n",
      "https://ieeexplore.ieee.org/document/8566011\n",
      "IEEE\n",
      "2018\n",
      "https://github.com/wroth8/dp-bnn\n",
      "Model-Intrinsic\n",
      "----\n",
      "Forget Unlearning: Towards True Data Deletion in Machine Learning\n",
      "https://arxiv.org/pdf/2210.08911.pdf\n",
      "ICLR\n",
      "2022\n",
      "-\n",
      "Data-Driven\n",
      "----\n",
      "PUMA: Performance Unchanged Model Augmentation for Training Data Removal\n",
      "https://ojs.aaai.org/index.php/AAAI/article/view/20846\n",
      "AAAI\n",
      "2022\n",
      "-\n",
      "Data-Driven\n",
      "----\n",
      "Certifiable Unlearning Pipelines for Logistic Regression: An Experimental Study\n",
      "https://www.mdpi.com/2504-4990/4/3/28\n",
      "MAKE\n",
      "2022\n",
      "https://version.helsinki.fi/mahadeva/unlearning-experiments\n",
      "Data-Driven\n",
      "----\n",
      "Zero-Shot Machine Unlearning\n",
      "https://arxiv.org/abs/2201.05629\n",
      "arXiv\n",
      "2022\n",
      "-\n",
      "Data-Driven\n",
      "----\n",
      "GRAPHEDITOR: An Efficient Graph Representation Learning and Unlearning Approach\n",
      "https://congweilin.github.io/CongWeilin.io/files/GraphEditor.pdf\n",
      "-\n",
      "2022\n",
      "https://anonymous.4open.science/r/GraphEditor-NeurIPS22-856E/README.md\n",
      "Data-Driven\n",
      "----\n",
      "Learning to Refit for Convex Learning Problems\n",
      "https://arxiv.org/abs/2111.12545\n",
      "arXiv\n",
      "2021\n",
      "-\n",
      "Data-Driven\n",
      "----\n",
      "Fast Yet Effective Machine Unlearning\n",
      "https://arxiv.org/abs/2111.08947\n",
      "arXiv\n",
      "2021\n",
      "-\n",
      "Data-Driven\n",
      "----\n",
      "SSSE: Efficiently Erasing Samples from Trained Machine Learning Models\n",
      "https://openreview.net/forum?id=GRMKEx3kEo\n",
      "NeurIPS\n",
      "2021\n",
      "-\n",
      "Data-Driven\n",
      "----\n",
      "Coded Machine Unlearning\n",
      "https://ieeexplore.ieee.org/document/9458237\n",
      "IEEE\n",
      "2021\n",
      "-\n",
      "Data-Driven\n",
      "----\n",
      "Machine Unlearning\n",
      "https://ieeexplore.ieee.org/document/9519428\n",
      "IEEE\n",
      "2021\n",
      "https://github.com/cleverhans-lab/machine-unlearning\n",
      "Data-Driven\n",
      "----\n",
      "How Does Data Augmentation Affect Privacy in Machine Learning?\n",
      "https://ojs.aaai.org/index.php/AAAI/article/view/17284/\n",
      "AAAI\n",
      "2021\n",
      "https://github.com/dayu11/MI_with_DA\n",
      "Data-Driven\n",
      "----\n",
      "Amnesiac Machine Learning\n",
      "https://ojs.aaai.org/index.php/AAAI/article/view/17371\n",
      "AAAI\n",
      "2021\n",
      "https://github.com/lmgraves/AmnesiacML\n",
      "Data-Driven\n",
      "----\n",
      "Unlearnable Examples: Making Personal Data Unexploitable\n",
      "https://arxiv.org/abs/2101.04898\n",
      "ICLR\n",
      "2021\n",
      "https://github.com/HanxunH/Unlearnable-Examples\n",
      "Data-Driven\n",
      "----\n",
      "Descent-to-Delete: Gradient-Based Methods for Machine Unlearning\n",
      "https://proceedings.mlr.press/v132/neel21a.html\n",
      "ALT\n",
      "2021\n",
      "-\n",
      "Data-Driven\n",
      "----\n",
      "Fawkes: Protecting Privacy against Unauthorized Deep Learning Models\n",
      "https://dl.acm.org/doi/abs/10.5555/3489212.3489302\n",
      "USENIX Sec. Sym.\n",
      "2020\n",
      "https://github.com/Shawn-Shan/fawkes\n",
      "Data-Driven\n",
      "----\n",
      "PrIU: A Provenance-Based Approach for Incrementally Updating Regression Models\n",
      "https://dl.acm.org/doi/abs/10.1145/3318464.3380571\n",
      "SIGMOD\n",
      "2020\n",
      "-\n",
      "Data-Driven\n",
      "----\n",
      "DeltaGrad: Rapid retraining of machine learning models\n",
      "https://proceedings.mlr.press/v119/wu20b.html\n",
      "ICML\n",
      "2020\n",
      "https://github.com/thuwuyinjun/DeltaGrad\n",
      "Data-Driven\n"
     ]
    }
   ],
   "source": [
    "for line in lines:\n",
    "    if line==\"Model-Agnostic\\n\" or line==\"Model-Intrinsic\\n\" or line==\"Data-Driven\\n\":\n",
    "        types=line[:-1]\n",
    "    else:\n",
    "        print('----')\n",
    "        ### title\n",
    "        title = re.search(r'\\[(.*?)\\]', line).group()[1:-1]\n",
    "\n",
    "        ### link to paper\n",
    "        link = re.search(r'\\((.*?)\\)', line).group()[1:-1]\n",
    "\n",
    "        try:\n",
    "        ### venue\n",
    "            venue = re.search(r'\\|\\s\\_(.*?)\\_', line).group()[3:-1]\n",
    "        except:\n",
    "            venue = '-'\n",
    "\n",
    "        ### year\n",
    "        year = re.search(r'\\s\\d{4}\\s', line).group()[1:-1]\n",
    "\n",
    "        ### code\n",
    "        res = re.search(r'\\]\\]\\((.*?)\\)', line)\n",
    "        if res is None:\n",
    "            code = '-'\n",
    "        else:\n",
    "            code = res.group()[3:-1]\n",
    "\n",
    "#         ### type\n",
    "#         type_slash_idx = findOccurrences(line, '|')[-2:]\n",
    "#         types = line[type_slash_idx[0]:type_slash_idx[1]][2:-1].lstrip()\n",
    "\n",
    "        print(title)\n",
    "        print(link)\n",
    "        print(venue)\n",
    "        print(year)\n",
    "        print(code)\n",
    "        print(types)\n",
    "\n",
    "        ### formation\n",
    "        f.write(\"                                                <tr>\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"                                                    <td><a href=\\\"{}\\\">{}</a></td>\".format(link, title))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"                                                    <td>{}</td>\".format(venue))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"                                                    <td>{}</td>\".format(year))\n",
    "        if code == '-':\n",
    "            f.write(\"                                                    <td class='code'>-</td>\".format(code))\n",
    "        else:\n",
    "            f.write(\"                                                    <td><a href=\\\"{}\\\">[Code]</a></td>\".format(code))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"                                                    <td>{}</td>\".format(types))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"                                                </tr>\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46abe031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
